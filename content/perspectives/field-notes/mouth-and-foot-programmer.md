---
title: "The Mouth-and-Foot Programmer（2008）"
date: 2008-09-16
---

> This piece was originally published on my early personal blog in 2008.  
> It reflects an early intuition that programming is fundamentally a cognitive and symbolic activity,  
> and that human value in computing should not be tightly bound to any specific physical interface.
> Long before voice interfaces or large language models existed,  
> this question already pointed toward a more general idea:  
> **interfaces are replaceable; cognition is not.**

## （中文）口足程式設計師

如果沒有手，你不知道什麼是擁抱的感覺。  
如果沒有手，你不知道生活中許多理所當然的動作原來都這麼麻煩。  
如果沒有手，你將是什麼樣的人？

某個節慶日，我百般無聊地窩在沙發上看電視，剛好看到公視介紹「口足畫家」。看著看著，思緒就這麼一偏、一轉，腦中冒出一個問題：

> 既然有口足畫家，那有沒有口足程式設計師？

在社會想像中，失去雙手的上肢身障者，似乎多半被引導成為口足畫家。  
但如果從技術本身來看，用腳寫程式真的比用腳畫畫困難嗎？

仔細想想，程式設計對雙手的依賴，其實遠低於繪畫。  
它不要求精細的力道控制，不要求角度與筆觸，只是敲擊、輸入，以及有限的二維操作（例如滑鼠定位）。  
在這些條件下，繪畫的難度反而高得多。

真正的問題只剩下一個：輸入。

如果無法輸入程式碼，就無從談起程式設計。  
但腳能操作的按鍵數量，本來就比手少，這並不是全新的問題——手機輸入法早已面對過同樣的限制。  
除了輸入速度較慢之外，大多數文字與符號需求其實都能被滿足。

而寫程式真正花時間的，從來不是打字，而是思考。

這樣看來，成為一名口足程式設計師，並非不可行。

真正的限制不在身體，而在介面設計。  
當時市面上幾乎所有「腳用輸入裝置」，都只是把「手的操作邏輯」原封不動地移植到腳上，而不是重新思考：  
**如果操作主體改變了，介面是否也該重新設計？**

即使對雙手健全的人而言，一個設計良好的腳用輸入裝置，也可能帶來新的便利。  
例如：雙手用來吃飯，眼睛閱讀螢幕上的文字，腳來翻頁。

---

## (English) The Mouth-and-Foot Programmer

If you have never lost your hands,  
you may not realize how many ordinary actions quietly depend on them.  
If you had no hands, who would you become?

In 2008, while casually watching public television during a holiday,  
I came across a documentary about mouth-and-foot painters—artists who paint using their mouths or feet due to upper-limb disabilities.

A simple question occurred to me:

> If there are mouth-and-foot painters, could there also be mouth-and-foot programmers?

In common social imagination, people who lose the use of their hands are often guided toward painting.  
But from a technical perspective, is programming with one’s feet actually harder than painting with one’s feet?

On closer inspection, programming places surprisingly low demands on fine motor skills.  
It does not require precise pressure control, angles, or strokes—only keystrokes, symbolic input, and limited two-dimensional movement (such as cursor positioning).  
By comparison, drawing and painting are far more physically demanding.

The real challenge is input.

If you cannot input code, you cannot program.  
But limited input is not a new problem.  
Mobile phones had already demonstrated that meaningful text and symbol input is possible with a small number of keys.  
Typing may be slower, but programming time is dominated by thinking, not typing.

From this perspective, the idea of a mouth-and-foot programmer is entirely plausible.

The true limitation lies not in the body, but in interface design.

At the time, most foot-based input devices simply replicated hand-based interaction models, instead of asking a more fundamental question:  
**If the operating body changes, should the interface change as well?**

Even for able-bodied users, a well-designed foot-based input system could expand everyday possibilities—  
hands occupied with eating, eyes reading a screen, feet turning the page.
